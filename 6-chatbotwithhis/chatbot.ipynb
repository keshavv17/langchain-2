{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71300c4",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec5c08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cf3a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x767581ad9be0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x767581ada7b0>, model_name='gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-It\", groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d3c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Krish! It's a pleasure to meet you.  That's a fascinating role!  \\n\\nAs a large language model, I'm always eager to learn more about how AI is being used in the world. What kind of projects are you working on?  \\n\\nPerhaps you could tell me about:\\n\\n* **The most exciting challenge you're facing in your work.**\\n* **A recent breakthrough or accomplishment you're proud of.**\\n* **What you think the future holds for AI engineering.**\\n\\n\\nI'm excited to hear your insights!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 22, 'total_tokens': 141, 'completion_time': 0.216363636, 'prompt_time': 0.001325851, 'queue_time': 0.248999548, 'total_time': 0.217689487}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2329ca5a-a42d-476d-ad0c-e1143a1cc27e-0', usage_metadata={'input_tokens': 22, 'output_tokens': 119, 'total_tokens': 141})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is krish and im a chief ai engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a69e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Keshav, and you are a Chief AI Engineer!  \\n\\nIs there anything else you'd like to know or discuss?  ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 161, 'total_tokens': 195, 'completion_time': 0.061818182, 'prompt_time': 0.004546752, 'queue_time': 0.247997367, 'total_time': 0.066364934}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0979814-2956-4ad6-b918-b155ff6b9a33-0', usage_metadata={'input_tokens': 161, 'output_tokens': 34, 'total_tokens': 195})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content = \"Hi my name is keshav, and im a chief ai engineer\"),\n",
    "    AIMessage(content=\"Hello Keshav! It's a pleasure to meet you.  That's a fascinating role!  \\n\\nAs a large language model, I'm always eager to learn more about how AI is being used in the world. What kind of projects are you working on?  \\n\\nPerhaps you could tell me about:\\n\\n* **The most exciting challenge you're facing in your work.**\\n* **A recent breakthrough or accomplishment you're proud of.**\\n* **What you think the future holds for AI engineering.**\\n\\n\\nI'm excited to hear your insights!\\n\"),\n",
    "    HumanMessage(content=\"hey, whats my name, what do i do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece03a1d",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78fffbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: int)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687bbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66fe540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Keshav! \\n\\nIt's great to meet you. Being an AI engineer is such a cutting-edge field. What kind of projects are you working on?  \\n\\nI'm always interested to hear what people are doing in the world of AI.  ðŸ˜„ \\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is keshav and im an ai engineer\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e933bf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Keshav.  ðŸ˜Š  I remember! \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 171, 'total_tokens': 188, 'completion_time': 0.030909091, 'prompt_time': 0.004450179, 'queue_time': 0.25329589, 'total_time': 0.03535927}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cb92544-b1c9-4373-8376-5b1d059067ce-0', usage_metadata={'input_tokens': 171, 'output_tokens': 17, 'total_tokens': 188})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2de40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name.\\n\\nIf you'd like to tell me your name, I'd be happy to use it! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 12, 'total_tokens': 55, 'completion_time': 0.078181818, 'prompt_time': 0.00116769, 'queue_time': 0.24656495, 'total_time': 0.079349508}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--bf5083e7-31f7-40f5-a8f1-070bcf084e2a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 43, 'total_tokens': 55})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the session id (config)\n",
    "config1= {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"whats my name\")],\n",
    "    config=config1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
